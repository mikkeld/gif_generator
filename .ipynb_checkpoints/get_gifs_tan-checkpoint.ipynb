{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.image as Image\n",
    "import keras\n",
    "%matplotlib inline\n",
    "import bcolz\n",
    "from scipy.misc import imresize\n",
    "from datetime import datetime, timedelta\n",
    "import h5py as h5py\n",
    "try:\n",
    "    utils\n",
    "except:\n",
    "    import utils\n",
    "else:    \n",
    "    reload(utils)\n",
    "    print 'utils has been reloaded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EMBEDDING CLASS TO BE USED\n",
    "class Embedding:\n",
    "    def __init__(self, topology='vgg16'):\n",
    "        self.topology = topology\n",
    "        self.network = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet',\n",
    "                                                      input_tensor=None,input_shape=None,\n",
    "                                                      pooling=None, classes=1000)\n",
    "        self.network.layers.pop() # Get rid of the classification layer\n",
    "        self.network.outputs = [self.network.layers[-1].output]\n",
    "        self.network.layers[-1].outbound_nodes = []\n",
    "        for layer in self.network.layers: layer.trainable=False\n",
    "    def get_vector(self, batch):\n",
    "        return self.network.predict(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "API_KEY = 'J9rmStnqj0ZhQFObVxh81O84hb7UQZjY'\n",
    "N_FILES = 100\n",
    "SEARCH_TERM = 'cat'\n",
    "api_path = \"http://api.giphy.com/v1/gifs/search?q={}&api_key={}&limit={}\".format(SEARCH_TERM, API_KEY, N_FILES)\n",
    "data = json.loads(urllib.urlopen(api_path).read())\n",
    "utils.save_files(data,SEARCH_TERM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for gif_file in os.listdir('gifs'):\n",
    "    gif_file_path 'gifs/'+gif_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process gif to series of images which can be \n",
    "# fed to netwok.\n",
    "gif_file = 'cat_93.gif'\n",
    "gif_file_path = 'gifs/'+gif_file\n",
    "frames = utils.processImage(gif_file_path,\n",
    "                            reshape_to_vgg=True,\n",
    "                            image_limit=20)\n",
    "print np.shape(frames)\n",
    "pyplot.imshow(frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = Embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "embedding_matrix = embeddings.get_vector(frames)\n",
    "# round(timedelta.total_seconds(datetime.now()-start_time)/60,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix[0:11,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape\n",
    "# in numpy slicing, last element is exclusive\n",
    "# ex x[0:2,:] = x[[0,1],:]\n",
    "max_index = embedding_matrix.shape[0]\n",
    "seq_length = 11 # 10 for training, 1 for the target\n",
    "data_arr = []\n",
    "for i in range(max_index-seq_length):\n",
    "    start_ix = i\n",
    "    end_ix = i+seq_length\n",
    "    target_ix = end_ix\n",
    "    data_arr.append(embedding_matrix[start_ix:end_ix,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data_arr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = bcolz.carray(data_arr, rootdir='data/bcolz_test2')\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.append(data_arr)\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0:3,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, root_dir=None):\n",
    "        if not root_dir:\n",
    "            raise ValueError('Please specify a data location.')\n",
    "        self.root_dir = root_dir \n",
    "        self.has_data = False\n",
    "        self._remaining = None\n",
    "        self._update()\n",
    "#         if self.root_dir:\n",
    "#             self._update()\n",
    "#             self.has_data = True\n",
    "                   \n",
    "    def add(self, data_arr):\n",
    "        if self.has_data:\n",
    "            self._append(data_arr)\n",
    "        else:\n",
    "            self._create(data_arr)\n",
    "            \n",
    "    def _create(self, data_arr):\n",
    "        try:\n",
    "            self.data = bcolz.carray(data_arr, rootdir=self.root_dir)\n",
    "            self.data.flush()\n",
    "            self.has_data=True\n",
    "        except:\n",
    "            raise\n",
    "            \n",
    "    def _update(self):\n",
    "        try:\n",
    "            self.data = bcolz.carray(rootdir=self.root_dir)\n",
    "            self.has_data=True\n",
    "        except IOError as err:\n",
    "            self.has_data = False\n",
    "            # print '[ERROR] There is no data in %s.'%(self.root_dir)\n",
    "            \n",
    "    def _append(self, data_arr):\n",
    "        self._update()\n",
    "        self.data.append(data_arr)\n",
    "        self.data.flush()\n",
    "    # TODO(tanozaslan) Change keyword replace, it is confusing with numpy build in\n",
    "    # function.\n",
    "    def reset_batch(self):\n",
    "        self._remaining = None\n",
    "        \n",
    "    def get_random_batch(self, batch_size=10, replace=True):\n",
    "        if batch_size > self.data.shape[0]:\n",
    "                raise ValueError('Batch size cannot be bigger than data size.')\n",
    "        data_size = self.data.shape[0]\n",
    "        vector_len = self.data.shape[1]\n",
    "        if replace:\n",
    "            batch_idxs = np.random.choice(data_size,batch_size,replace=False)\n",
    "        else:\n",
    "            if not self._remaining:\n",
    "                self._remaining = range(data_size)\n",
    "            batch_idxs = []\n",
    "            if len(self._remaining) < batch_size and len(self._remaining) > 0:\n",
    "                batch_idxs = self._remaining\n",
    "                np.random.shuffle(batch_idxs)\n",
    "                self._remaining = []\n",
    "            else:\n",
    "                for _ in range(batch_size):\n",
    "                    batch_idx = np.random.choice(range(len(self._remaining)),\n",
    "                                                 size=[1],\n",
    "                                                 replace=False)\n",
    "                    batch_idxs.append(self._remaining.pop(batch_idx))\n",
    "            if len(self._remaining) == 0:\n",
    "                self.reset_batch()\n",
    "                \n",
    "        data = self.data[batch_idxs,:,0:vector_len-1]\n",
    "        target = self.data[batch_idxs,:,vector_len-1:vector_len]\n",
    "        return data,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = Dataset(root_dir='data/bcolz_test2')\n",
    "data_set.has_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set=None\n",
    "if data_set:\n",
    "    data_set.append(data_arr)\n",
    "else:\n",
    "    data_set = Dataset(root_dir='data/bcolz_test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "(100, 10, 4096) (100, 1, 4096)\n"
     ]
    }
   ],
   "source": [
    "print len(data_set.data)\n",
    "data,target=data_set.get_random_batch(batch_size=100,replace=False)\n",
    "print data.shape,target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
